#investment #trading #automation #parsing #sentimentAnalysis #telegram #golang #AI #dataAggregation #spam

# Автоматизация сбора и анализа инвестиционной информации

```table-of-contents
```

## Обзор текущей системы

Вы создали систему, которая агрегирует информацию из различных Telegram-каналов, посвященных инвестициям и спекуляциям. Система работает следующим образом:

1.  **Подписка на каналы:** Вы подписаны на множество каналов, связанных с инвестициями.
2.  **Копирование сообщений:** Используется бот-копировщик, который пересылает сообщения в ваш личный канал, если они содержат определенные ключевые слова. Это создает своего рода дайджест.
3.  **Агрегация платных каналов:** Система также умеет агрегировать платные каналы, обходя механизмы защиты от копирования и предоставляя доступ подписчикам через личный кабинет.
4.  **Распознавание аудио**: Интегрирован AI для распознавания аудиосообщений.
5.  **Парсинг Smart-Lab**: Реализован парсер для сайта Smart-Lab.
6.  **Копирование виджетов**: Копируются виджеты с графиками, например, график Tesla с Finviz и других источников (около 15).
7.  **Граббер профильных каналов:** Собран список из 800 тысяч аккаунтов Telegram.
8.  **Инструменты для спама:** Приобретены программы для спама и изучены методы их применения.

## Проблемы текущей системы

Несмотря на продвинутость, система имеет ряд недостатков:

1.  **Избыточность информации:** Пересылка сообщений по ключевым словам приводит к дублированию информации из разных каналов.
2.  **Пропуск важных сообщений:** Диалоги, не содержащие ключевых слов, могут содержать важную информацию, но пропускаются системой.
3.  **Ручная обработка:** Требуется ручной просмотр большого объема информации, что снижает эффективность.

## Потенциальные улучшения и направления развития

Основная цель – создание системы, приближенной к функционалу "кнопки Бабло", то есть автоматизированного инструмента для принятия инвестиционных решений. Для этого можно использовать несколько подходов:

### 1. Анализ тональности (Sentiment Analysis)

**Описание:** Добавление модуля анализа тональности (сентимента) текста позволит оценивать эмоциональную окраску сообщений и выявлять потенциально важные новости или мнения.

**Шаги реализации:**

1.  **Выбор библиотеки/API:** Существуют готовые библиотеки и API для анализа тональности, например, на основе машинного обучения. Примеры:
    *   **Dostoevsky:** Русскоязычная библиотека для Python. [https://github.com/bureaucratic-labs/dostoevsky](https://github.com/bureaucratic-labs/dostoevsky)
    *   **TextBlob (для английского):** Простая в использовании библиотека для Python. [https://textblob.readthedocs.io/en/dev/](https://textblob.readthedocs.io/en/dev/)
    *   **Google Cloud Natural Language API:** Платный, но мощный сервис от Google. [https://cloud.google.com/natural-language](https://cloud.google.com/natural-language)
    *   **Amazon Comprehend:** Аналогичный сервис от Amazon. [https://aws.amazon.com/ru/comprehend/](https://aws.amazon.com/ru/comprehend/)
    *   **SentiStrength:** специализированный инструмент. [http://sentistrength.wlv.ac.uk/](http://sentistrength.wlv.ac.uk/)
2.  **Интеграция:** Интегрировать выбранный инструмент в существующую систему копирования.
3.  **Обучение (при необходимости):** Если используется библиотека, требующая обучения, подготовить набор данных для обучения на специфическом финансовом сленге.
4.  **Обработка сообщений:** При пересылке сообщения анализировать его тональность и добавлять метку (например, "позитивный", "негативный", "нейтральный") или числовую оценку.
5.  **Фильтрация:** Предоставить пользователю возможность фильтровать сообщения по тональности.

**Плюсы:**

*   Выявление скрытых инсайтов.
*   Автоматизация определения важных новостей.

**Минусы:**

*   Сложность интерпретации сарказма и иронии.
*   Необходимость адаптации к финансовому сленгу.
*   Вероятность ложных срабатываний.

### 2. Отслеживание формализованных новостей и действий

**Описание:** Сосредоточиться на новостях и действиях, которые можно представить в виде четких бинарных событий (да/нет).  Например, покупка/продажа акций инсайдером, изменение рейтинга компании, публикация отчетности.

**Шаги реализации:**

1.  **Определение источников:** Составить список сайтов и каналов, публикующих формализованную информацию (например, сайты раскрытия информации, новостные агентства).
2.  **Разработка парсеров:** Создать парсеры для каждого источника, извлекающие нужные данные.
3.  **Создание базы данных:** Создать базу данных для хранения событий.
4.  **Интеграция с системой оповещений:** Настроить систему оповещений, которая будет уведомлять пользователя о наступлении определенных событий.
5.  **Автоматический трейдинг (опционально):** В перспективе можно интегрировать систему с торговым терминалом для автоматического совершения сделок на основе полученных данных.

**Плюсы:**

*   Четкость и однозначность данных.
*   Возможность автоматизации принятия решений.

**Минусы:**

*   Ограниченность круга отслеживаемых событий.
*   Сложность парсинга некоторых источников.

### 3. Агрегация данных по персоналиям (как у beststocks.ru)

**Описание:**  beststocks.ru (аналог tipranks.com)  отслеживает торговые активности известных инвесторов и аналитиков.  Можно реализовать подобный функционал, собирая информацию о действиях ключевых фигур в инвестиционном мире.

**Шаги реализации:**

1.  **Составление списка персоналий:**  Определить круг лиц, за чьими действиями будет вестись наблюдение.
2.  **Поиск источников:**  Найти источники информации о сделках этих персоналий (сайты раскрытия информации, новостные ресурсы, социальные сети).
3.  **Разработка парсеров:**  Создать парсеры для извлечения данных о сделках.
4.  **Создание базы данных:**  Создать базу данных для хранения информации о сделках.
5.  **Визуализация:**  Разработать интерфейс для удобного просмотра и анализа данных.

**Плюсы:**

*   Доступ к информации о действиях "умных денег".
*   Возможность копирования стратегий успешных инвесторов.

**Минусы:**

*   Сложность поиска и обработки информации.
*   Задержка в получении данных (информация может публиковаться с задержкой).
*   Необходимость учета законодательных ограничений (инсайдерская информация).

### 4. Использование AI для анализа неструктурированных данных

**Описание:** Применить методы обработки естественного языка (NLP) и машинного обучения для извлечения информации из неструктурированных источников, таких как новостные статьи, отчеты аналитиков, обсуждения на форумах.

**Шаги реализации:**

1.  **Выбор инструментов:** Выбрать библиотеки и API для NLP и машинного обучения. Примеры:
    *   **spaCy:** Мощная библиотека для NLP. [https://spacy.io/](https://spacy.io/)
    *   **NLTK:** Еще одна популярная библиотека для NLP. [https://www.nltk.org/](https://www.nltk.org/)
    *   **Scikit-learn:** Библиотека для машинного обучения. [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)
    *   **TensorFlow/Keras/PyTorch:** Фреймворки для глубокого обучения.
2.  **Разработка моделей:**  Создать модели машинного обучения для решения конкретных задач, например:
    *   **Классификация новостей:**  Определение тематики и важности новостей.
    *   **Извлечение именованных сущностей (NER):**  Выделение из текста названий компаний, имен людей, сумм сделок и т.д.
    *   **Суммаризация текста:**  Создание кратких выжимок из больших текстов.
3.  **Интеграция:**  Интегрировать модели в систему сбора и обработки данных.

**Плюсы:**

*   Возможность обработки больших объемов неструктурированной информации.
*   Выявление скрытых закономерностей и трендов.

**Минусы:**

*   Высокая сложность разработки и обучения моделей.
*   Требования к вычислительным ресурсам.

## Пример реализации на Go (упрощенный)

Рассмотрим пример реализации парсера для сайта раскрытия информации (например, [https://www.e-disclosure.ru/](https://www.e-disclosure.ru/)) и добавления данных в базу данных.

```go
package main

import (
	"fmt"
	"log"
	"net/http"
	"strings"

	"github.com/PuerkitoBio/goquery"
	"database/sql"
	_ "github.com/go-sql-driver/mysql" // Или другой драйвер, в зависимости от используемой СУБД
)

// Структура для хранения информации о сообщении
type DisclosureMessage struct {
	ID          int
	Company     string
	Title       string
	Date        string
	URL         string
	MessageType string // Тип сообщения (например, "Существенный факт")
}

// Функция для парсинга страницы раскрытия информации
func parseDisclosurePage(url string) ([]DisclosureMessage, error) {
	// Отправляем GET-запрос
	res, err := http.Get(url)
	if err != nil {
		return nil, err
	}
	defer res.Body.Close()
	if res.StatusCode != 200 {
		return nil, fmt.Errorf("status code error: %d %s", res.StatusCode, res.Status)
	}

	// Загружаем HTML-документ
	doc, err := goquery.NewDocumentFromReader(res.Body)
	if err != nil {
		return nil, err
	}

	var messages []DisclosureMessage

	// Ищем элементы таблицы с сообщениями (селекторы нужно уточнить для конкретного сайта)
	doc.Find("table.zebra tbody tr").Each(func(i int, s *goquery.Selection) {
		message := DisclosureMessage{}

		// Извлекаем данные из ячеек таблицы
		message.Date = s.Find("td:nth-child(1)").Text()
		message.Company = s.Find("td:nth-child(2) a").Text()
		message.Title = s.Find("td:nth-child(3) a").Text()
		link, _ := s.Find("td:nth-child(3) a").Attr("href")
		message.URL = "https://www.e-disclosure.ru" + link // Формируем полный URL
        message.MessageType = s.Find("td:nth-child(4)").Text()

		messages = append(messages, message)
	})

	return messages, nil
}

// Функция для сохранения сообщения в базу данных
func saveMessageToDB(db *sql.DB, message DisclosureMessage) error {
	// Подготавливаем SQL-запрос (синтаксис может отличаться в зависимости от СУБД)
    query := "INSERT INTO disclosure_messages (company, title, date, url, message_type) VALUES (?, ?, ?, ?, ?)"
    stmt, err := db.Prepare(query)

	if err != nil {
		return err
	}
	defer stmt.Close()

	// Выполняем запрос
	_, err = stmt.Exec(message.Company, message.Title, message.Date, message.URL, message.MessageType)
	return err
}


func main() {
	// Параметры подключения к базе данных (замените на свои)
    db, err := sql.Open("mysql", "user:password@tcp(127.0.0.1:3306)/database_name")

	if err != nil {
		log.Fatal(err)
	}
	defer db.Close()
    err = db.Ping() //проверяем соединение
    if err != nil {
        log.Fatal(err)
    }

	// URL страницы для парсинга (пример)
	url := "https://www.e-disclosure.ru/portal/eventtype.aspx?EventId=A-B-C-D" // Пример URL

	// Парсим страницу
	messages, err := parseDisclosurePage(url)
	if err != nil {
		log.Fatal(err)
	}

	// Сохраняем сообщения в базу данных
	for _, message := range messages {
		err := saveMessageToDB(db, message)
		if err != nil {
			log.Println("Error saving message:", err)
		} else {
            fmt.Printf("Saved message: %+v\n", message) //%+v -  выводит и название поля и значение
        }
	}
}

```

**Пояснения к коду:**

1.  **Импорты:** Импортируются необходимые библиотеки:
    *   `net/http` для выполнения HTTP-запросов.
    *   `github.com/PuerkitoBio/goquery` для парсинга HTML (аналог jQuery для Go).  Устанавливается командой: `go get github.com/PuerkitoBio/goquery`
    *   `database/sql` – стандартный пакет Go для работы с базами данных.
    *   `github.com/go-sql-driver/mysql` – драйвер MySQL для пакета `database/sql`. Устанавливается: `go get github.com/go-sql-driver/mysql`.  Вместо него можно использовать драйвер для PostgreSQL (`github.com/lib/pq`) или другой.
2.  **Структура `DisclosureMessage`:**  Определяет структуру для хранения данных о сообщении.
3.  **Функция `parseDisclosurePage`:**
    *   Выполняет GET-запрос к указанному URL.
    *   Использует `goquery` для парсинга HTML-кода страницы.
    *   Находит таблицу с сообщениями (селекторы `table.zebra tbody tr` нужно будет уточнить, изучив HTML-код целевой страницы).
    *   Итерирует по строкам таблицы, извлекая данные из ячеек (название компании, заголовок, дату, ссылку).  Используются CSS-селекторы (`td:nth-child(1)`, `td:nth-child(2) a` и т.д.).  Их тоже нужно будет уточнить.
    *   Формирует полный URL сообщения.
    *   Возвращает слайс (срез) структур `DisclosureMessage`.
4.  **Функция `saveMessageToDB`:**
    *   Принимает объект базы данных (`*sql.DB`) и структуру `DisclosureMessage`.
    *   Подготавливает SQL-запрос для вставки данных в таблицу `disclosure_messages`.  *Важно*:  название таблицы и полей нужно заменить на свои.
    *   Выполняет запрос, передавая данные из структуры `DisclosureMessage`.
5.  **Функция `main`:**
    *   Открывает соединение с базой данных MySQL (параметры подключения нужно заменить на свои).
    *   Вызывает функцию `parseDisclosurePage` для парсинга страницы.
    *   Вызывает функцию `saveMessageToDB` для сохранения каждого сообщения в базу данных.
    *   Обрабатывает ошибки.

**Дальнейшие шаги:**

1.  **Изучение HTML-структуры целевых сайтов:**  Необходимо тщательно изучить HTML-код сайтов, с которых планируется извлекать данные, чтобы определить правильные CSS-селекторы для элементов.  Для этого можно использовать инструменты разработчика в браузере (обычно вызываются клавишей F12).
2.  **Обработка ошибок:**  В коде примера обработка ошибок базовая.  В реальном приложении нужно добавить более детальную обработку, логирование, возможно, повторные попытки при временных сбоях.
3.  **Пагинация:**  Если на сайте есть пагинация (разбиение списка сообщений на несколько страниц), нужно реализовать обход всех страниц.  Это можно сделать, анализируя ссылки на следующие страницы и рекурсивно вызывая функцию парсинга.
4.  **Параллелизм:**  Для ускорения парсинга можно использовать горутины (goroutines) и каналы (channels) для параллельной обработки нескольких страниц или нескольких сообщений.
5.  **Регулярные выражения:**  В некоторых случаях для извлечения данных из текста может потребоваться использовать регулярные выражения.  В Go для этого есть пакет `regexp`.
6.  **Защита от блокировки:**  Сайты могут блокировать парсеры, которые делают слишком много запросов за короткое время.  Чтобы избежать этого, можно:
    *   Добавлять задержки между запросами (использовать `time.Sleep`).
    *   Использовать прокси-серверы.
    *   Менять User-Agent (заголовок запроса, идентифицирующий клиента).
7.  **Работа с другими базами данных:** Вместо MySQL можно использовать PostgreSQL, SQLite или другую СУБД.  Для этого нужно будет изменить строку подключения к базе данных и, возможно, синтаксис SQL-запросов.
8. **Интерфейс**: Реализация удобного интерфейса для пользователей.

Этот пример демонстрирует базовый принцип парсинга и сохранения данных.  Его нужно адаптировать под конкретные задачи и источники данных.

## Заключение

Автоматизация сбора и анализа инвестиционной информации - сложная, но перспективная задача.  Вы уже проделали большую работу, создав основу системы.  Развитие системы в описанных направлениях позволит значительно повысить ее эффективность и приблизить к желаемому результату – созданию инструмента, помогающего принимать обоснованные инвестиционные решения.

```old
Посылаю очередной сигнал в космос 🙏

Я подписан на все каналы про инвестиции и спекуляции. Наваял копировальщик года 3 назад. Если где-то есть упоминание ключевых слов, то в мой канал выполняется пересылка сообщения. Получается некий дайджест.

Как-то это помогает? Если бы запилить анализ диалогов для выявления сентимента. А так вручную читать много дублей и пропустишь важное, когда диалог без ключевого слова.

Имеет смысл следить за формализуемыми новостями и действиями (например в автоследах). Тогда их можно оценивать дискретно да-нет.

А ещё он умеет агрегировать платники: с премодерацией, с защитой от выявления копирования, с личным кабинетом для подписчиков. Я страдал 11 месяцев. 👨‍💻

Не дает покоя идея автоматизировать сбор и анализ информации. Я теперь еще и аудио умею распознавать через AI. И парсить смарт-лаб - не проблема. И есть копировальщик виджетов. Например, график Теслы с ФинВиза (и еще штук 15 разных источников).

Ещё сделал грабёр профильных каналов. Собрал 800 тыс. аккаунтов. Купил прогу для спама и вводный курс, как её применять. Собрал все грабли. Ирония в том, что я сам боролся со спамерами в личных сообщениях mamba.ru лет 15 тому назад, понимаю их методы.

Конечная цель - кнопка Бабло. Коган объявил, что уже три месяца продает свой продукт какой-то. Московская Биржа тоже пилит аля Блумберг Терминал. Есть beststocks.ru - локализованный tipranks.com - Рыбаков вложил 77 миллионов долларов. Суть в том что мониторят вообще все интернеты на предмет торговых активностей по персоналиям.

Инвестиционные консультации - огромный бизнес в Америке. Мурад хвастал, что тупо на автоследе поднимает 5 лямов в месяц. Но у Когана вроде есть своя лицензия брокера, а Мурад тупо отдает больше половины брокеру, да.
```