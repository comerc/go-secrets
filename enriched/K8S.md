#kubernetes #cgroups #go #linux #scheduler #cpu #memory #containers #pods #optimization

# Оптимизация Go-приложений в Kubernetes

```table-of-contents
```

## Введение

В данном ответе рассматривается оптимизация Go-приложений, работающих в среде Kubernetes. Kubernetes предоставляет удобные средства для развертывания и масштабирования приложений, но требует тщательной настройки для эффективного использования ресурсов и обеспечения высокой производительности. Ключевыми аспектами являются понимание работы планировщика Linux [[CFS (Completely Fair Scheduler)]], механизма [[Cgroups]], а также правильная настройка параметров CPU и Memory для контейнеров и подов. Отдельное внимание уделяется параметрам Go: `GOMAXPROCS` и `GOMEMLIMIT`.

## Kubernetes и управление ресурсами

Kubernetes – это система оркестровки контейнеров, которая абстрагируется от физических или виртуальных машин и позволяет управлять приложениями, упакованными в [[Containers]].  Развертывание приложений часто осуществляется с помощью команды `kubectl apply`. Масштабирование может быть реализовано как на уровне отдельных приложений (с помощью [[HPA (Horizontal Pod Autoscaling)]]), так и на уровне всего кластера (с помощью [[CA (Cluster Autoscaling)]]).

### Cgroups (Control Groups)

[[Cgroups]] – это механизм ядра Linux, который позволяет организовывать процессы в иерархические группы и управлять распределением ресурсов (CPU, память, I/O) между этими группами. Cgroups являются основой для контейнеризации.  Иерархия Cgroups представляет собой дерево, где каждой группе выделяется определенное количество ресурсов.

###  CFS (Completely Fair Scheduler)

[[CFS (Completely Fair Scheduler)]] – это планировщик процессов в ядре Linux, который стремится обеспечить справедливое распределение процессорного времени между всеми выполняющимися задачами. CFS использует красно-черное дерево для хранения задач, отсортированных по времени выполнения (vruntime). Задачи, которые выполнялись меньше всего, находятся в левой части дерева и имеют приоритет при выборе следующей задачи для выполнения.  CFS моделирует "идеальный, точный многозадачный процессор" на реальном оборудовании.

### CFS Bandwidth Control

CFS Bandwidth Control – это механизм, позволяющий ограничить использование CPU для группы процессов (Cgroup). Он работает путем назначения квоты (Quota) процессорного времени на определенный период (Period). Если группа исчерпывает свою квоту до окончания периода, ее процессы тротлятся (Throttle), то есть приостанавливаются до начала следующего периода.

В Kubernetes эти параметры настраиваются через:

*   `cpu.cfs_period_us` (глобальная установка)
*   `cpu.cfs_quota_us` (установка для каждого пода)

### Requests и Limits в Kubernetes

В Kubernetes для каждого контейнера можно определить Requests и Limits для CPU и памяти:

*   **Requests:** Указывают планировщику Kubernetes, сколько ресурсов (в среднем) требуется контейнеру. Планировщик использует эту информацию для выбора узла ([[Nodes]]), на котором будет запущен под ([[Pods]]). Под не будет размещен на узле, если его Requests превышают доступный Capacity узла.
*   **Limits:** Указывают максимальное количество ресурсов, которое может использовать контейнер. При превышении лимита по CPU контейнер будет тротлиться (CFS Bandwidth Control). При превышении лимита по памяти контейнер может быть остановлен (OOM - Out Of Memory).

## Оптимизация Go-приложений

### GOMAXPROCS

`GOMAXPROCS` – это переменная среды в Go, которая определяет количество операционных системных потоков, которые могут одновременно выполнять код Go. По умолчанию, `GOMAXPROCS` равен количеству логических ядер процессора. Однако, в среде Kubernetes, где CPU может быть ограничен через Limits, `GOMAXPROCS` должен быть настроен в соответствии с этими ограничениями, чтобы избежать троттлинга.

Библиотека [uber-go/automaxprocs](https://github.com/uber-go/automaxprocs) автоматически устанавливает `GOMAXPROCS` в соответствии с ограничениями CPU, заданными в Kubernetes (через cgroups). Это помогает избежать проблем с производительностью, связанных с троттлингом.

### GOMEMLIMIT

`GOMEMLIMIT` - это переменная среды в Go, которая контролирует общий объем памяти, который может использовать приложение Go, прежде чем сборщик мусора (GC) начнет более агрессивно освобождать неиспользуемую память.

### Рекомендации по оптимизации

1.  **Всегда определяйте CPU и Memory Requests.** Это необходимо для эффективного распределения ресурсов в кластере и предотвращения ситуаций, когда одни приложения потребляют слишком много ресурсов, а другие испытывают нехватку.

2.  **Используйте CPU Limits в связке с GOMAXPROCS.** Убедитесь, что `GOMAXPROCS` соответствует ограничениям CPU, установленным для контейнера. Используйте `uber-go/automaxprocs` для автоматической настройки.

3.  **Устанавливайте Memory Limits равными Requests.** Это предотвращает выселение (eviction) подов с одной ноды на другую из-за нехватки памяти (MemoryPressure). При выселении, под завершается и перезапускается на другом узле, что может привести к временной недоступности приложения.

4.  **Мониторьте CPU Throttling ваших контейнеров.** Это позволяет выявлять проблемы с производительностью на ранних стадиях и корректировать настройки.

5. **Контролируйте значение GOMEMLIMIT.**

6.  **Экспериментируйте с разными значениями CPU Limits, GOMAXPROCS и GOMEMLIMIT.** Оптимальные значения зависят от профиля нагрузки приложения. Анализируйте следующие метрики:

    *   Server Latency (50, 90, 99, 99.9 персентили)
    *   CPU Usage
    *   GC Duration

7.  **Используйте целые числа для CPU Limit.** Дробные значения могут приводить к непредсказуемому поведению планировщика.

## Пример конфигурации Kubernetes

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-go-app
spec:
  containers:
  - name: my-go-container
    image: my-go-image:latest
    resources:
      requests:
        memory: "256Mi"
        cpu: "1"
      limits:
        memory: "256Mi" # Memory Limits = Requests
        cpu: "1" # Целое число
    env:
      - name: GOMAXPROCS
        value: "1" # Соответствует CPU Limit
```

В этом примере Requests и Limits по памяти установлены равными 256MiB. CPU Limit установлен в 1 (одно ядро), и `GOMAXPROCS` также установлен в 1, чтобы соответствовать ограничению CPU.

## Автоматизация настройки GOMEMLIMIT

В настоящее время нет широко известной библиотеки, аналогичной `uber-go/automaxprocs` для автоматической настройки `GOMEMLIMIT`. Однако, есть проект [KimMachineGun/automemlimit](https://github.com/KimMachineGun/automemlimit), который предлагает автоматическую установку `GOMEMLIMIT` на основе ограничений памяти cgroups.

Также возможно создание собственного решения для автоматизации настройки `GOMEMLIMIT`.  Этот процесс может включать в себя:

1.  Запуск приложения с различными значениями `GOMEMLIMIT`.
2.  Мониторинг использования памяти и производительности (например, с помощью `pprof`).
3.  Определение оптимального значения на основе собранных данных.
4.  Автоматическое применение оптимального значения при запуске приложения.

## Service Mesh

[[Service Mesh]] – это выделенный слой инфраструктуры, который упрощает взаимодействие между сервисами (микросервисами) в распределенной системе. Service Mesh обеспечивает маршрутизацию запросов, безопасность, сбор метрик (задержка, частота ошибок, использование ресурсов), распределенное трассирование и журналирование. Он позволяет отделить логику управления трафиком от бизнес-логики приложения.

## Заключение

Оптимизация Go-приложений в Kubernetes требует комплексного подхода, включающего понимание работы планировщика Linux, механизма Cgroups, а также правильную настройку параметров CPU и Memory для контейнеров и подов.  Тщательная настройка `GOMAXPROCS` и `GOMEMLIMIT`, а также мониторинг производительности, позволяют добиться максимальной эффективности и стабильности работы приложений.

```old
https://youtu.be/MHn-taXfQ8o?t=3748

Определения в контексте Kubernetes:

- **CFS (Completely Fair Scheduler)**: Это планировщик процессов, реализованный Ingo Molnar и включенный в Linux 2.6.23. Он заменил код интерактивности предыдущего планировщика SCHED_OTHER. CFS моделирует \"идеальный, точный многозадачный процессор\" на реальном оборудовании. Основная логика выбора задач CFS основана на значении p->se.vruntime, и она очень проста: всегда пытается запустить задачу с наименьшим значением p->se.vruntime (то есть задачу, которая выполнялась меньше всего).

- **GMP**: В контексте Kubernetes я не нашел определение для GMP. Возможно, вы имели в виду другой термин или акроним.

- **CPU & MEM Limits**: В Kubernetes вы можете указать ограничения на использование ресурсов для каждого контейнера в поде, включая CPU и память. Ограничения на CPU и память определяют максимальное количество ресурсов, которые контейнер может использовать.

- **Containers**: Контейнеры - это стандартизированные исполняемые компоненты, которые объединяют исходный код приложения с библиотеками операционной системы. В Kubernetes каждый контейнер изолирован от других процессов и работает на компьютере, физическом сервере или виртуальной машине.

- **Pods**: Поды - это наименьшие развертываемые единицы вычислений, которые вы можете создать и управлять в Kubernetes. Под (как стая китов или стручок гороха) - это группа из одного или нескольких контейнеров с общим хранилищем и сетевыми ресурсами, а также спецификацией того, как запускать контейнеры.

- **Nodes**: Узел - это рабочая машина в Kubernetes и может быть виртуальной или физической машиной, в зависимости от кластера. Каждый узел управляется планом управления и содержит услуги, необходимые для запуска подов.

- **Requests**: Запросы обычно используются для определения среднего потребления. Когда вы указываете запрос на ресурсы для контейнеров в поде, планировщик Kubernetes использует эту информацию, чтобы решить, на каком узле разместить под.

---

При администрировании кластера Kubernetes администратор может настроить два параметра:

\`\`\`
cpu.cfs_period_us (глобальная установка);
cpu.cfs_quota_us (установка для каждого пода).
\`\`\`

[runtime: make GOMAXPROCS cfs-aware on GOOS=linux](https://github.com/golang/go/issues/33803) - на сегодня проблему решает uber-go/automaxprocs

Рекомендации:

- Requests: всегда определяйте CPU & MEM requests
- CPU Limits: использовать в связке с GOMAXPROCS (иначе тротлятся)
- MEM Limits: выставлять равным requests (иначе убиваются)
- Мониторить CPU Throttling ваших контейнеров
- Всегда контролируйте значение GOMAXPROCS
- Оптимальный GOMAXPROCS всегда зависит от вашего контекста
- Выставляйте целые числа в CPU Limit
- Пробуйте разные значения, пока не найдёте оптимальную комбинацию:
  - Server Latency (50, 90, 99, 99.9 персентили)
  - CPU Usage
  - GC Duration

---

- [Как использовать ресурсы Kubernetes по максимуму для работы с Go-приложениями](https://habr.com/ru/companies/sbermarket/articles/773648/)

Выкатывается приложение буквально одной командой kubectl apply, что очень удобно. Плюс, можно масштабировать как индивидуальное приложение — с помощью HPA (Horizontal Pod Autoscaling), так и сам кластер, — с помощью CA (Cluster Autoscaling), увеличивая количество нод по мере потребности.

CFS (Completely Fair Scheduler) берет задачи, которые были исполнены на процессоре минимальное количество времени, вытаскивает их из левой части дерева, исполняет на процессоре и потом возвращает в правую часть дерева. Таким образом происходит движение задач по дереву и равномерное по длительности исполнение каждой задачи.

А что если мы не хотим, чтобы все процессы в нашей системе имели одинаковый приоритет? Для таких случаев был придуман прекрасный механизм под названием Cgroups.

Cgroups (Control Group) — это механизм для организации процессов в иерархию и контролируемого распределения ресурсов по этой иерархии в соответствии с конфигурацией. Эта иерархия представляет из себя дерево. В нём в каждой группе выделяется какое-то количество ресурсов, которыми эта группа может пользоваться. Механизм Сgroups — это основа для контейнеризации приложений.

> Важно понимать, что планировщик не будет размещать под с Requests, которые превышают этот остаточный Capacity на ноде. Соответственно, если Capacity на одной ноде не хватает, значит планировщик пойдет на другую ноду. Если свободных нод не найдено, тогда планировщик с помощью механизма Cluster autoscaling создаст новую ноду и там разместит под.

![Исполнение Goroutines](./assets/goroutines-on-k8s.png)

CFS Bandwidth Control — это механизм, который позволяет определять потолок CPU, используемого группой (Cgroup). Механизм заключается в том, что Cgroup выдается квота (Quota) процессорного времени за определенный отрезок времени (Period). Когда вся квота использована, потоки в группе ограничиваются, или тротлятся (Throttle), что значит, что они не будут исполняться на процессоре остаток этого периода (Period). Как только исчерпана квота за один период, нужно ждать следующего периода, когда можно будет пользоваться новой квотой.

![Пример конфигурации CFS](./assets/cfs-config.png)

Limits нужны для выставления жестких порогов утилизации ресурсов контейнерами. При достижении этих порогов по процессору контейнер будет тротлиться, а по достижению лимитов по памяти контейнер будет останавливаться.

Оптимизируем ресурсы Kubernetes:

✅ Всегда определяйте CPU, Memory Requests. Это нужно для более эффективного использования ресурсов.

✅ CPU Limits используйте в связке с GOMAXPROCS. Всегда нужно контролировать, сколько CPU Limits, сколько GOMAXPROCS сейчас приложение использует.

✅ Memory Limits выставляйте равными Requests. Это поможет избежать выселений подов с одной ноды на другую.

✅ Мониторьте CPU Throttling ваших контейнеров. Это поможет выявлять проблемы с производительностью на ранних стадиях.

Для Go-приложений:

✅ Всегда контролируйте значение GOMAXPROCS

✅ Оптимальный GOMAXPROCS всегда зависит от вашего контекста, у каждого приложения свой профиль нагрузки

✅ Пробуйте разные значения, деплойте их на проде, пока не найдете оптимальную комбинацию. Во время эскпериментов, смотрите и анализируйте графики по:

— Server Latency (50, 90, 99, 99.9 персентили)
— CPU Usage
— GC Duration

Выставляя оптимальные значения, мы оптимизируем бюджет на Kubernetes и делаем его более предсказуемым, а также повышаем производительность Go приложений в целом.

---

Service Mesh - это специализированный слой инфраструктуры, предназначенный для облегчения общения между сервисами или микросервисами. В отличие от других систем управления этим общением, Service Mesh является выделенным слоем инфраструктуры, встроенным прямо в приложение.

Service Mesh обеспечивает следующие функции:

- Оптимизация общения между различными частями приложения.
- Маршрутизация запросов от одного сервиса к другому.
- Обеспечение безопасного общения между сервисами.
- Сбор метрик, таких как задержка, частота ошибок и использование ресурсов.
- Выполнение распределенного трассирования для просмотра полного пути и времени запросов через несколько сервисов.
- Регистрация событий сервиса в журналах для аудита, отладки и соблюдения требований к соблюдению нормативных требований.

Service Mesh обычно используется в распределенных системах, состоящих из микросервисов.

---

[Kubernetes 1.28: sidecar-контейнеры возвращаются?](https://habr.com/ru/companies/vk/articles/772574/)


--- 

Kubernetes

- Удобство
  - Абстракция над физическими или виртуальными машинами
  - Выкатка приложений одной командой (kubectl apply)
- Масштабируемость
  - HPA - горизонтальное масштабирование подов
  - CA - cluster autoscaling - горизонтальное масштабирование нод

Но иногда это...

- CPU Throttling
- Container Evicted (MemoryPressure)
- Зашкаливающие 99 персентили по длительности ответа сервера
- Непредсказуемое масштабирование кластера
- Или наоборот - простаивающие ресурсы на нодах с потреблением CPU, Memory менее 50%

---

На данный момент нет широко известной библиотеки, аналогичной uber-go/automaxprocs для автоматической настройки GOMEMLIMIT. GOMAXPROCS обычно настраивается для оптимизации использования CPU, тогда как GOMEMLIMIT относится к управлению памятью, и автоматическая настройка может быть более сложной из-за разнообразия требований к памяти разных приложений.

Для автоматизации подбора GOMEMLIMIT, вы можете рассмотреть написание собственного скрипта или программы, которая будет:

1. Запускать ваше приложение с различными значениями GOMEMLIMIT.
2. Мониторить использование памяти и производительность.
3. Определять оптимальное значение на основе собранных данных.

Этот процесс может включать в себя тестирование под нагрузкой и анализ результатов для разных сценариев использования вашего приложения. Ключевыми метриками для анализа могут быть производительность, задержка и потребление памяти.

Для сбора и анализа данных можно использовать библиотеки и инструменты, такие как pprof для профилирования памяти в Go, а также различные системы мониторинга и анализа производительности.

Написание подобного инструмента потребует глубокого понимания работы вашего приложения и его требований к памяти, а также может потребовать постоянной настройки и адаптации под изменения в приложении.

--- 

Automatically set GOMEMLIMIT to match Linux cgroups(7) memory limit. https://github.com/KimMachineGun/automemlimit
```